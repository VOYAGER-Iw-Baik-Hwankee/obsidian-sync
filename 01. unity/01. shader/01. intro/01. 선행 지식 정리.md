---
tags:
  - Unity
  - Shader
date: 2025-02-23
---

> [!info] 머리말
> "The Unity Shaders Bible." 이라는 책을 읽고 정리한 내용이다.

---
##  01. 폴리곤 객체의 속성
*Properties of a **polygonal** object*
**폴리곤**은 선분으로 둘러쌓인, 닫힌 평면 도형을 의미한다.
어원부터가 그리스어 *πολύγωνος*에서 유래됐다고 한다. (*Poly (많은) + Gnow (각도)*)

![[Pasted image 20250223232155.png]]

**기본(Primitive) 타입**은 폴리곤으로 구성된 **3차원 지오메트릭 객체**이다.
유니티 (블렌더, 마야 등)에서는 다음과 같은 기본 타입이 있다:
- Spheres
- Boxes
- Quads
- Cylinders
- Capsules

이 모든 객체는 서로 생김새는 다르지만, 갖고 있는 속성은 비슷하다:
- Vertices
- Tangents
- Normals
- UV coordinates
- Color

> [!TIP] 위 데이터는 **메쉬(Mesh)** 라는 데이터 타입 내에 저장된다.
> 이 모든 속성들은 모두 셰이더 내에서 독립적으로 접근이 가능하다. (Vector 타입 변수로 값을 저장할 수도 있다!)
> 다시 말해, 저 속성들을 변경하는 것만으로도 아주 멋진 효과를 낼 수 있다는 뜻이다. 

![[Pasted image 20250223233400.png]]

---
## 02. 정점
*Vertices*
정점은 2d 혹은 3d 공간에서, 객체의 표면 면적을 정의할 수 있는 "**점(Point)**"의 집합이다.
이 점의 특징은 다음과 같은 특징을 갖고 있다.
- Transform 컴포넌트의 자식
- 객체의 전체 **부피(Volume)** 중심에 따라 정의된 "위치"가 있다.

Transform 노드는 객체의 피봇에 따라 *위치(position)*, *회전(rotation)*, *크기(scale)* 를 정의한다.
Transform 노드의 자식인 Shape 노드에는 객체의 부피에 대한 지오메트리 속성이 포함된다. 

> [!TIP] 지오메트리 속성이란?
> **Geometry Attribute**: 객체의 부피에 대한 정점의 위치를 의미.

그래서 우리는 Transform 노드를 통해 객체의 **정점 집합 (Vertex Set)** 을 이동, 회전 및 크기를 조정할 수 있다.

여기서 HLSL의 `POSITION[n]`시맨틱은 정점의 위치(*부피와 관련된*)에 대한 정보를 제공한다.

> [!TIP] 시맨틱이란?
> **Semantic**: 해당 코드가 어떤 의미를 지니고, 전체 프로그램 중 어떤 역할을 하는가를 나타내는 것.
> 여기서 관점은 프로그램이 아닌, "**해당 코드**"이다. 
> `foo(100)` -> `GetDamaged(100)` 이런 식으로 적어야 제대로 기능 파악을 할 수 있다~ 이런 뜻이다.

![[Pasted image 20250224001757.png]]

---
## 03. 법선
*Normal*
**법선(Nomal)** 은 폴리곤 표면의 수직 벡터이다. 
이는 **면(Face)** 또는 **정점(Vertex)** 의 방향을 결정하는데 사용된다.

> [!TIP] 표면의 방향을 왜 알아야 할까?
> 3d 모델링 툴을 보면, 법선을 가시적으로 볼 수 있게끔 하는 옵션이 있다.
> 모델러는 법선을 통해 해당 표면이 제대로 된 방향을 보고 있는지 여부를 파악할 수 있다.

![[Pasted image 20250224010555.png]]

---
## 04. 접선
*Tangent*
**접선(Tangent)** 은 지오메트리 표면의 UV 중, `U` 방향을 따르는 정규화된 벡터이다.

![[Pasted image 20250224220012.png]]
- 초록: Binormal
- 파랑: Normal
- 빨강: Tangent

> [!WARNING] Binormal은 셰이더를 통해 지원되지 않는다.
> 그러므로, Normal과 Tangent를 통해 계산하여 얻어야 한다.

---
## 05. UV 좌표
**UV 좌표**는 3차원 객체에 입힌 2차원 텍스쳐를 생각하면 된다.
UV 좌표는 텍스쳐 맵 위에서 메쉬의 각 정점에 해당하는 **텍셀(Texel)** 을 제어하는 기준점 역할을 한다.

여기서 UV 좌표 위에 정점을 배치하는 작업을 **UV 매핑**이라 한다.
- 객체 메쉬를 2차원 공간에 펼치는 작업
- 펼친 메쉬를 텍스쳐 위에 올려, 편집 및 구성

셰이더에서는 이 속성을 통해 3d 모델에 텍스쳐를 배치할 수 있다. (단순 정보만을 저장할 수도 있다)

![[Pasted image 20250224222501.png]]

> [!TIP] 우측이 바로 UV 좌표이고, 가로가 `U`, 세로가 `V`를 의미한다.

UV 좌표의 면적은 `0.0f ~ 1.0f` 사이의 범위이다.
여기서 `0.0f`는 시작점을 의미하고, `1.0f`는 끝점을 의미한다.

![[Pasted image 20250224222820.png]]

---
## 06. 버텍스 컬러
객체는 조명, 혹은 다른 색상과의 곱셈을 통해 영향을 받게 된다.
여기서 영향을 받은 색상을 바로 **버텍스 컬러(Vertex Color)** 라고 한다.

이는 기본적으로 흰색이고, RGBA 채널의 값은 `1.0f`이다.

![[Pasted image 20250224223132.png]]

---
## 07. 렌더 파이프라인 아키텍쳐
*Render Pipeline Architecture*
Unity에는 `Built-in RP`, `Universal RP` (구 `Lightweight`), `High-Definition RP` 이렇게 세 가지 렌더 파이프라인이 있다.

> [!INFO] 파이프라인이란?
> **파이프라인**은 하나의 거대한 작업을 수행하기까지의 과정을 의미한다.

> [!TIP] 그렇다면.. 렌더 파이프라인이란?
> **렌더 파이프라인**은 폴리곤 객체가 컴퓨터 화면에 렌더링될 때까지 거치는 전체 프로세스를 의미한다. 

![[Pasted image 20250224223832.png]]

각 렌더 파이프라인에는 고유의 특성이 있다. 그래서, 사용중인 유형에 따라 `Material properties`, `Light sources`, `Textures`, 그리고 셰이더 내 모든 기능들이 다르게 동작하게 된다.
즉, 화면에서 비친 오브젝트의 모양이 달라지고, 또 최적화가 이루어지는 정도도 달라진다.

보편적인 **실시간 렌더링 엔진(Real-time rendering Engine)** 의 "**렌더 파이프라인 아키텍쳐**"는 다음과 같이 총 4단계로 나뉜다.
1. **애플리케이션 단계(Application stage)**
2. **지오메트리 처리 단계(Geometry processing phase)**
3. **래스터화 단계(Rasterization stage)**
4. **픽셀 처리 단계(Pixel processing stage)**

![[Pasted image 20250224225008.png]]

---
## 08. 애플리케이션 단계
*Application Stage*
**애플리케이션 단계**는 **CPU**에서 시작한다. 
그리고, 씬 내에서 발생하는 **대부분의 작업**을 담당한다.

> [!INFO] 여기서 말하는 대부분의 작업이란..
> - 콜리전 충돌
> - 텍스쳐 애니메이션
> - 키보드, 마우스 입력

다시 렌더 파이프라인으로 돌아오자.
애플리케이션 단계는 "저장된 메모리 데이터"를 읽어들이는 일을 한다.
> [!TIP] 이 메모리 데이터는 이 단계를 거쳐 **기본 타입(Primitive: 삼각형, 선, 정점)** 이 된다.

애플리케이션 단계가 끝나면, 이 모든 데이터 정보는 "**지오메트리 처리 단계**"로 넘어간다.
거기서 **행렬 곱셈**을 통해 정점의 `Transform`을 생성한다.

![[Pasted image 20250224230005.png]]

---
## 09. 지오메트리 처리 단계
*Geometry processing phase*
우리가 컴퓨터 화면을 통해 보는 이미지는 GPU가 CPU에 요청하여 만들어진 것이다.
이 과정은 다음 두 가지 단계를 거쳐 수행된다.
1. 지오메트리 처리 단계부터 픽셀 처리까지 수행될 "**렌더링 상태**"를 **설정(Configuration)** 한다.
2. 그리고, 화면에 객체를 그린다!

쉽게 설명하자면, 지오메트리 처리 단계의 시작은 GPU에서 발생한다.
GPU에서는 객체의 정점 처리를 담당한다. 이 작업은 다음 4가지 과정을 거쳐 처리된다.
1. **정점 셰이딩(Vertex Shading)**
2. **투영(Projection)**
3. **클리핑(Clipping)**
4. **화면 매핑(Screen mapping)**

![[Pasted image 20250224231836.png]]

이전 애플리케이션 단계에서 만들어진 **기본 타입(Primitive)** 을 두고, 정점 셰이딩 작업을 수행한다.

> [!TIP] 정점 셰이딩은 사실 "**정점 셰이더 단계(Vertex Shader Stage)**"로 더 잘 알려져 있다.

여기서 정점 셰이딩은 다음 두 가지 작업을 수행한다.
1. 객체의 정점 위치를 계산한다.
2. 컴퓨터 화면에 **투사(Project)** 할 수 있도록, 해당 **트랜스폼**의 **위치(Position)** 를 다른 공간 좌표로 변환한다.

정점 셰이딩 작업 중, `Normal`, `Tangent`, `UV coord`  등, 다음 단계로 전달할 속성을 선택할 수 있다.

이 프로세스에서 **투영(Projection)** 및 **클리핑(Clipping)** 이 발생한다.
이는 전적으로 카메라의 속성, `Perspective`인지, `Orthographic (Parallel)`인지 여부에 따라 달라진다.

> [!TIP] 사실 전체 렌더링 프로세스는 "**뷰-공간(View-Space)**"라 하는 곳에서만 일어난다.
> 다시말해, 이 모든 과정은 **카메라 프러스텀(Frustum, 절두체)** 내에 있는 요소를 대상으로만 발생한다.




---



